{"name":"Omicron-Spirograph","tagline":"A UI framework for precisely creating, controlling, and compiling particle system configurations.","body":"###From Spirograph to Particle System Framework:\r\n- what started as a responsive flow-field of illuminated particles designed for the Calistoga Springs event Luminescent Playground (Sept 21-23, 2013) is now a solid tool for configuring particle systems.\r\n- The documentation contained in this README reflects this transition from single project to underlying framework.\r\n- Requires name change since original names no longer apply to the current project (OmiCron-Spirograph and Juggling Molecules).  Potential replacements:\r\n  - FlowConfig\r\n  - LuxDust\r\n  - suggestions?\r\n\r\n###Documentation:\r\n- [images of user interaction, pre-event install, screenshots and diagrams from development ](http://www.flickr.com/photos/jaycody9/sets/72157635574816773/)\r\n- [vids (screen recordings and tests)](http://youtu.be/oneMByLSmEg)\r\n\r\n###Juggling Molecules\r\n- A responsive flow-field of illuminated particles designed for the Calistoga Springs' festival Luminescent Playground held Sept 20-23, 2013\r\n- the interface is a combination of gesture control supplied by a dancer's movement, and knob turning by participants using controls on an iPad.\r\n- The design originally called for the use of the podium sized OmiCron Interface, which would sit somewhere on the edge of the dance floor enticing users with its 7 large knobs and 4 glowing buttons.   \r\n- The original design also called for an iPad interface to control the remain 50 variables not intended for public consumption.\r\n- The OmiCron controls were scrapped, and we ended up designing the iPad controls for public use.  For the event, we attached the iPad to a clamp and attached the clamp to a tripod which presented the iPad for the user at about chest height. To help users deal with the overwhelming number of variables, we created 100 presets, many pre-populated with configurations prior to the event. \r\n- Original plans also included an semi-autonomous 3D spirograph pattern called a SpiroLight.  We were interested in expressing lifelike spontaneous behavior, something that would act as if it were aware of the dancers and their movements.  The documentation that follows includes ideas and strategies for this feature.\r\n\r\n###Hardware and Software required:\r\n- Mac Mini\r\n- Kinect Depth Sensor\r\n- Processing 2.0.3\r\n- SimpleOpenNI 1.96\r\n- iPad running TouchOSC\r\n- Projector\r\n- Rigging gear, power cables, VGA cables\r\n- Rubbermaid container to house the gear and keep it dry (outdoor event and it did rain)\r\n- 150 inch Portable rear projection screen\r\n- [Deprecated]:\r\n\t- [OmiCron The Interface](http://www.flickr.com/photos/jaycody9/sets/72157632699562712/)\r\n\r\n\r\n###Interactions:\r\n0. Dancer with OmiCron Controller\r\n1. Dancer with SpiroLight\r\n2. Dancer with Particles\r\n3. Particles with SpiroLight\r\n\t- Autonomous Vehicles AVOID OR PURSUE SpiroLight (Omicron Control)\r\n\t- When emerging from and avoiding spiroLight, particles steer toward Dancer\r\n\t- When emerging from and avoiding dancer, particles steer toward Spirolight.  When within range of outer most arm, particles accelerate like additive flashes of light and disappear inside spirolight.  Born again from Dancer's movement (optical flow)\r\n4. OmiCron with SpiroLight\r\n5. OmiCron with Particles\r\n\r\n\r\n###OmiCron: Map Controls to SpiroLight:\r\n- [] Button shuffles ratios for specified tier\r\n\t- where on the circle is arm connected? (make that a Perlin Noise function where button down progresses through perlin noise for all variables.\r\n- [] First tier Red knobs control overall size of spiroLight, mass, and steering ability toward target.  Mass gets bigger, slower it moves, the larger the circle, the larger the entire spiroLight  (as opposed to following closest point, which changes the size of spiroLight because of perspective being further away, but does not change the mass or the periods)\r\n- [] Knobs control Magnitude of all the vectors, while buttons control location within each variables range\r\n- [] Snap Button = Reverse Emitter Location from Tier 3 to Dancer.\r\n\t- when Emitter Origin is in SpiroLight, particles flock to Dancer\r\n\t- Particles follow path along edges up dancer and out of spirolight\r\n- [] Tier 1 = Red, Tier 2 = Green, Tier 3 = Blue\r\n- [] Each of the 3 omiCron buttons will change ratios (angular velocities, magnitude) for that color\r\n\t- eg Green Line From Tier 1 to Tier 2, and Green Line from Tier 2 to Tier 3 are:  \r\n\t\t- 1:1 in length, 1:1 in angular velocity, and are IN PHASE \r\n\t\t- 1:2 in length, 1:-2 in angular velocity, and are out of phase by 90degrees\r\n\t\t- 1:sqrt2 in length, 1:1.618 in angular velocity, and are out of phase by 180\r\n- [] Knobs: Red(Left and Right) Green(L,R), Blue(L,R) control the rotational velocity and distance to next teir.\r\n- [] Ohmite Knob controls the parameters of the flow field (somehow) and/or z-axis rotation\r\n- [] Add remainder of tier 2 and 3\r\n- Omicrons controls are mapped to the parameters of a spirograph-like pattern projected on a rear projection screen.  Dancers control the location of the pattern by way of the closest point in a 3D point cloud (ie the pattern will follow their hand if their hand contains the point closest to the Kinect sensor.  Dancers can also interact with a particle system whose behavior is controlled by a depth informed flow field.  Dancer's distance and velocity determine the behavior of the particles.\r\n- Create SpiroLight structure from Fractal Recursion??\r\n\t- [Fractal Recursion  |  Shiffman](https://vimeo.com/64424402) \r\n- **OmiCron Structure:**\r\n\t- [] Add extra lights to the bottom of OmiCron (since the device WILL be in an open field)\r\n\t\t- [] use a second Arduino??  Yes.\r\n\t- [] Add Handles\r\n\t- [] Bring extra batteries\r\n\t- [] bring usb mouse and keyboard just in case\r\n\t- [] bring Blue Tooth\r\n\r\n\r\n###SpiroLight:\r\n- **SpiroLight Forces:**\r\n\t- AstralLines (rotating arms):\r\n\t\t- arm length mapped to Velocity's Magnitude such that arms stretch when accelerating and shrink when decelerating (or vice versa).\r\n\t\t- Perlin Noise the mapping of acceleration to arm length such that perlin noise wanders along a continuum of MaxSpeed = MaxLength AND MaxSpeed = Min Length \r\n\t\t- Arm Rotation to Perlin Noise\r\n\t\t- Add the SCALE function to simulate 3D\r\n\t\t- Arm pivot point on circle wanders\r\n\t- Tier 1 Location Vectors have 4 control modes: (4 types of Forces that act upon primary location vector)\r\n\t\t1. TEST MODE:  Follow Mouse (ie sub(location, mouse))\r\n\t\t2. DANCER MODE:  \r\n\t\t\t- Follow/ PursueClosest Point in Point Cloud (controlled by dancer)\r\n\t\t\t- Evade closest point Dancer\r\n\t\t3. NULL USER MODE:  Perlin Noise (which can be used to inform all the arms and rotations)\r\n\t\t4. OMICRON ONLY MODE: (or FP-13 Mode) or Touch OSC:  No Kinect Attached, no dancer.  Forces mapped to RedKnob Left and Right for (x,y)\r\n- **SpiroLight with FlowField.**  \r\n\t- Instead of constant angular velocity, SpiroLight joints can respond to the Flow Field with their own steering force.  The joints are vehicles that check in a ask, 'does the flow field bellow have information for me?  If not, then keep steady pace, otherwise, use flow field as desired velocity'.  Everytime spirolight sweeps over the dancer, the movements will adjust.  Or the colors will change to show the outline of the body.  If assign color variation to optical flow and sillouette, then the resulting blendMode(ADD) would be sufficient to change all the underlying pixels, effectively showing the dancers body.\r\n\t\r\n- **SpiroLight Parameters and Controls:**\r\n\t- Inner sphere of 3D Hypotrochoid:\r\n\t\t- diameter -> User-N's distance from Kinect \r\n\t\t- velocity -> informed by velocity, location, and gravitational pull (determined by mass (from diameter) of User-N's center of gravity\r\n\t\t\t- use Center of Gravity velocity to inform direction and speed of ball rolling inside of sphere of a 3D Hypotrochoid\r\n\t\t- location of traced point in center sphere:\r\n\t\t\t- informed by Omicron controls OR\r\n\t\t\t- set center of gravity to be an xyz point inside a ball.\r\n\t\t- color and weight of traced point -> Omicron\r\n\r\n\t- Outer Sphere of 3D Hypotrochoid:\r\n\t\t- diameter -> distance between User-N's center of gravity and body part furthest away from User-N's center of gravity\r\n\t\t- location -> follows User-N\r\n\r\n\t- Parameter Options: \r\n\t\t- map the traced point to the corner of an Emblem (Snaps image) such that each of 3 users control one corner of an image with their individually controlled  nested sphere. \r\n\t\t- Make each User's center of gravity a single cusp in an n-cusp hypocycloid.\r\n\t\t\t- http://demonstrations.wolfram.com/EpicycloidsFromAnEnvelopeOfLines/\r\n\t\t- Spirolight parameters effected by the presence of other Spirolights; creates interweaving patterns.  \r\n\t\t- line thickness controlled by Kinect depth info\r\n\t\t- Traced line is occluded when it passes behind the User!!! user appears to be inside the Spirolight. \r\n\t\t- If user occludes the animation based on depth, then the outline created by User's body may br enough to depict the human form in negative space. Thus, no need for extra pixels. \r\n\t\t- Each User gets their own Spirolight (up to 3)\r\n\t\t- Create a 3-cusp epicycloid that remains 3-cusp while the distance between the cusps change (i.e., each cusp is the center of a moving body).  What other variables would have to change?\r\n\r\n- **Spirograph Definitions:**\r\n\t- **Hypocycloids:**\r\n\t\t- http://mathworld.wolfram.com/Hypocycloid.html\r\n\t\t- Coin inside a ring; tracing a point on circumference of coin\r\n\t\t- An n-cusped hypocycloid has radiusA / radiusB = n.\r\n\t\t\t- Thus, a 5 pointed star has is a hypocycloid whose ring's radius is 5x the radius of the coin inside.\r\n\t- **Hypotrochoids:**\r\n\t\t- http://mathworld.wolfram.com/Hypotrochoid.html\r\n\t\t- Coin inside a ring; tracing a point either inside or outside the perimeter of the coin\r\n\t- **Epicycloids:**\r\n\t\t- http://mathworld.wolfram.com/Epicycloid.html\r\n\t\t- Coin outside a ring; tracing a point on circumference of coin\r\n\t- **Epitrochoids:**\r\n\t\t- http://mathworld.wolfram.com/Epitrochoid.html\r\n\t\t- Coin outside of ring; tracing a point either inside or outside the perimeter of coin\r\n\r\n###SpiroLight + Dancer:\r\n- **Specific Arms Always remain in contact with the DANCER and EDGE DETECT PATH FOLLOW.**  \r\n\t- **arrives and path follows along the edge of dancer's body with one of it's arms (or 2)!!**  The SpiroLight follows the dancer and when it arrives, it's arms lock on to the edges and path follow.  Could cover and encircle the dancer like an octopus.  OR it grows NEW arms that remain in constant contact with user as the rest of the SpiroLight floats around.  Instead of harmonic monition, the arm follows the outline of the user.  see PATHFOLLOWING using the DOT PRODUCT\r\n\t- Some parts of the SpiroLight seek the dancer and some parts evade the dancer, so the thing is constantly investigating AND keeping it's distance.  If the Tier 1 Location Vector brings spiro closer to dancer, then arms that are repelled with flock together and move away while arms that are attracted will get closer.\r\n\t\t- AND the closer the arm, the greater the connetion, the brighter.\r\n\t\t- Whichever arm is path following along body will have perlin noise generated organic branching.\r\n\t- AND Particle System coming from dancer ALWAYS remains in contact with spiroLight\r\n\t- where spiroLight is attracted to some point in the flow field that also guides the particles coming from Dancer\r\n- **Dancer's Movement Also Affects Size and Brightness of SpiroLight**\r\n\t- Use the Frame Differencing already used to inform the particle system\r\n\t- The same threshold velocity which triggers particles also brightens and expands the SpiroLight\r\n\r\n\r\n\r\n###Optical Flow:  (Kinect + Dancer)\r\n- **Using Optical Flow:**\r\n\t- with change in depth, not just change in frame!!!  Frame differencing in the z-axis!!**  \r\n\t- Frame AND GreyScale Differencing for Depth Changes that are not along the x,y, but are instead, back and forth from the sensor.\r\n\t- [] RealTime 3D Optical Flow on a point cloud (color = point velocity; or color denotes movement direction and alpha denotes point velocity)\r\n\t- [] If movement > threshold, calc magnitude and orientation of gradient, \r\n\t- If movement > threshold, generate particle whose color equals the color of reference image and whose velocity is informed by the flow field.\r\n\t- **Color Code the Optical Flow**\r\n\t\t- see the UCF Computer Vision lect at minute 4.  Movement left to right right to left are different colors.  \r\n\t\t- Method is known as color coding vectors when velocity is mapped to the color intensity\r\n\t- Use Optical FLow to create Motion Based Segmentation (show me only what's moving)\r\n\t- Brightness Constancy Assumption f(x,y,z) = f(x + dx, y + dy, t + dt)\r\n\r\n- **Examples of Optical FLow:**\r\n\t- [Optical Flow Field + FLocking + Reference Image  |  YouTube](http://www.youtube.com/watch?v=2xs0fcmgKC0)\r\n\t- [Optical Flow Field - handForce affects an object's velocity  |  YouTube](http://www.youtube.com/watch?v=Edl6aWL1pjo)\r\n\t- [Structure From Motion Using Optical Flow  |  Shows Image, Smoothed Image, MotionVectors  YouTube](http://www.youtube.com/watch?v=qhoC-YetpnM)\r\n\t- [UCF Computer Vision lect.6 Optical Flow](http://www.youtube.com/watch?v=5VyLAH8BhF8)\r\n\t- [OpenCV Optical Flow Tutorial for the Lucas-Kanade Algorithm](http://dasl.mem.drexel.edu/~noahKuntz/openCVTut9.html)\r\n\t\t- The LK tracker uses three assumptions, brightness constancy between the same pixels from one frame to the next, small movements between frames (requiring image pyramids to track larger movements), and spatial coherence, thats points near each other are on the same surface. Then the basic concept of the tracker is to estimate the velocity of a moving pixel by the ratio of the derivative of the intensity over time divided by the derivative of the intensity over space. \r\n\t- [Optical FLow Estimation Tutorial  |  pdf](http://www.cs.toronto.edu/pub/jepson/teaching/vision/2503/opticalFlow.pdf)\r\n\t- [Computing Optical Flow with the OpenCV Library  |  Stavans, Stanford AI Lab](http://robots.stanford.edu/cs223b05/notes/CS%20223-B%20T1%20stavens_opencv_optical_flow.pdf)\r\n\t- [Calculating Small Optical Flow  |  tutorial pdf](http://www.cs.umd.edu/~djacobs/CMSC426/OpticalFlow.pdf)\r\n\t- [SimpleFlow: A Non-iterative, Sublinear Optical Flow Algorithm  |  Computer Graphics UC Berkeley](http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/)\r\n\t- [Optical FLow and the Methods of Calculating  |  wikipedia](http://en.wikipedia.org/wiki/Optical_flow)\r\n\t- [Images of Optical FLow](https://www.google.com/search?q=optical+flow&safe=off&tbm=isch&tbo=u&source=univ&sa=X&ei=3lcxUrneJeqWigLPxICADg&ved=0CEUQsAQ&biw=2128&bih=1203&sei=HFgxUsvZKOfgiALE9ICwBw#imgdii=_)\r\n\r\n\r\n- **Pseudo Code for Optical Flow:**\r\n\t- Horn & Shunck Optical Flow Algorithm\r\n\t\t- Brightness Constancy Assumption f(x,y,z) = f(x + dx, y + dy, t + dt)\r\n\t\t- Taylor Series\r\n\t1. Smooth Image with gausian blur\r\n\t2. Compute derivative of filtered image\r\n\t3. Find magnitude and orientation of gradient\r\n\t4. Apply 'non-maximum' suppression\r\n\r\n____________________________\r\n\r\n\r\n- **Point Cloud:**\r\n\t- We may keep the 2D world by pulling the 3D info from Kinect but projeting into 2D world.  Z-axis can convert to size instead of distance. \r\n\t- [] Make closest point in point cloud the desired target such that: \r\n\t- [] Create a Vector Field as function of depth\r\n\t- [] Build Library for Depth related Forces\r\n\t- [] In the abscence of movement (frame differencing < threshold), then SpiroLight moves towards Dancer (b/c it seeks dancer's closest point to sensor)\r\n\t- [] Assign a movie to the depth greyScale such that changing grey plays movie back or forward.  Use this to mask out the dancer's white outline.\r\n\r\n>```steering force = desired velocity - current velocity```\r\n\r\n- **Kinect-Projector Calibration**\r\n\t- [Kinect Projector Dance  |  YouTube Demo of the calibration tool](http://youtu.be/FnulH8TrZVo)\r\n\t- [Interactive Projection Mapping Test  |  YouTube  LOOK FOR FEEDBACK LOOP at 2:20](http://www.youtube.com/watch?v=e_QdqYWWZJI)\r\n\t- [Kinect Calibration Tool and Tutorials |  by prince_MIO](http://princemio.net/portfolio/kinect_projector_dance/)\r\n\r\n- **Kinect Tutorials:**\r\n\t- [Kinect Depth Selection in Processing](http://vimeo.com/17087533)\r\n\t- [Kinect Interaction](http://www.vimeo.com/groups/kinect)\r\n\t- [Background Replacement with Kinect](http://vimeo.com/17270320)\r\n\t- [Augmented Reality and Information Visualization](http://www.youtube.com/watch?v=z-aBUyrhcj0&feature=related)\r\n\r\n###FlowField Calculation:\r\n- accumulate forces from a variety of causes:  **spiroLight-Field**, **dancer-Field**, **noise-Field**\r\n\t1. **(spiroLight-Field)**  SpiroLight's Affect on the Flow Field:\r\n\t\t- affects the flowfield like iron flakes in a magnetic field.  \r\n\t\t- Particles located further away follow a longer circuitous route. \r\n\t\t- Field Vector Magnitudes along the path to SpiroLight increase as their distance to Spirolight decreases (particles accelerate as they approach)\r\n\t2. **(dancer-Field)**  Dancer's affect on the FlowField:\r\n\t\t- Dancers generate their own FlowField inside the Global Field.  Once calculated, the dancer's vector field is (ADDED?? SUBTRACTED?) to/from the SpiroLight Field \r\n\t\t- Flow Vectors within the boundary of the dancer's body align themselves with the magnitude and orientation of the body's depth gradients (pointing uphill)\r\n\t\t- Dancer's Flow Vectors\r\n- Future Fields: **flowMap-Field**, **feedbackLoop-Field**, **windSensor-Field**\r\n\t- **flowMap-Field**\r\n\t\t- Use a reference image as a map to inform the field.  (ex. set direction according to brightness)\r\n\t\t- Examples:\r\n\t\t\t- [Flow Maps:  The Evolution of a Pattern Language  |  screenshots from a Processing sketch on flickr](http://www.flickr.com/photos/jaycody9/sets/72157629880409223/)\r\n\t\t\t- []\r\n\r\n\t- **feedbackLoop-Field**\r\n\t\t- feedback loop generated via a vector field?  probably not the best implementation.  A get() and set() feedback loop likely effective\r\n\t\t- however, a feedback layer can be produced that is specific to a certain kind of particle while ignoring other particles.  Perhaps particles generated in the negative diretion or a feeback pattern that only affects the frame differencing frames.\r\n\r\n\t- **windSensor-Field** \r\n\t\t- or **anemos-Field**\r\n\t\t- anemometer - a device used for measuring wind speed; from the Greek word ANEMOS, meaning wind\r\n\t\t- we'd use Gill Instrument's WindMaster 3-Axis Ultrasonic Wind Speed and Direction Sensor  [dataSheet](http://www.gillinstruments.com/data/datasheets/WindMaster-Web-Datasheet.pdf)\r\n\t\t\t- provides wind speed and direction data\r\n\t\t\t- wind speed (0-45m/s and 0-65m/s)\r\n\t\t\t- 0-359º wind direction range (no dead band)\r\n\t\t\t- wind direction (0-359º) data. \r\n\t\t\t- 3-vector outputs (U, V, W), \r\n\t\t\t- data logging software\r\n\t\t\t- Speed of sound and sonic temperature outputs.\r\n\t\t\t- Optional analogue inputs and outputs are available with either 12 or 14 bit resolution.\r\n\t\t\t- This 3D sonic anemometer is ideally suited to the measurement of air turbulence around bridges, buildings, wind turbine sites, building ventilation control systems, meteorological and flux measurement sites.\r\n\t\t\t- [3-Axis Wind Speed Sensor Brochure](http://www.gillinstruments.com/data/datasheets/3_AXIS_web.pdf)\r\n\t\t\t\r\n- How do we create one field from multiple fields?\r\n- [] flow field points to spirolight, unless located on dancer within min-max range\r\n- [] if dancer in field, then vector mag is depth and direction points to the edge.  once at the edge, particle moves toward spirolight according to background flow field\r\n- [] flow field vectors increase in magnitude as they approach spirolight such that particles accelerate toward the light\r\n- [] particle steering force and maxspeed change relative to their proximity to spirolight\r\n\r\n###Feedback Loop as PGraphic Layer\r\n- Frame Difference Seeds Feedback Loop\r\n\t- create new Pgraphic to hold only the frame differencing information such that currentPgraphic - previousPGraphic = differencePGraphic.  Then get() pixels from this layer and updatePixels with itself, creating a feedback loop\r\n\t- assign noise as velocity of Feedback Layer\r\n- [] Create an array of PImages, each containing the previous frame to create a 5 sec sample of dancer + depth.  then rotate along the z-axis (see La Danse Kinect on vimeo).\r\n- [] How will CenterPiece-SpiroLight interact with the dancer's body?\r\n\t- blendMode(ADD)\r\n- [] dancer is mask for reference image\r\n\r\n\r\n\r\n\r\n\r\n###Code:\r\n- Use createGraphics() to return a PGraphics object.  Unlike the main drawing surface, this surface retains transparency!  That means SpiroLight can fade without fading the particle system\r\n\r\n- **ToDo(Owen):**\r\n\t- [] Particle System!  particle.lookup(PVector particleLocation); // will return a PVector force derived from the Flow Field state at that particle's location.  USE THE FORCE to inform acceleration to inform velocity to inform location.  \r\n\r\n\r\n\r\n- **ToDo(Installation):**\r\n\r\n###Code Snippets:\r\n\r\n```spiroLight.applyForce(force);\r\n``` \r\n\r\n- // with zero net force, object remains still or at constant velocity.  spiroLight object receives the force and hands it to the object's method applyForce(PVector force) where the force gets accumulated by acceleration with acceleration.add(force) (such that force informs acceleration, acceleration informs velocity, velocity informs location)\r\n\r\n- accumulate the net force (but only for any specific frame).  Update should end with acc.mag(0); to clear the forces that the acceleration vector has accumulated.\r\n\r\n```\r\nvoid applyForce (PVector force) {\r\n\tPVector newForceBasedOnObjectMass = PVector.div(force, mass); \r\n\t\t\t\t// b/c more force required to move larger mass.\r\n\tacceleration.add(force);\r\n}\r\nvoid update() {\r\nvelocity.add(acceleration);\r\nlocation.add(velocity);\r\n}\r\n```\r\n\r\n- A simpler For-Loop Syntax for an Array:\r\n``` for (SpiroLight spiro : Spiros){}  // for every SpiroLight spiro in the array Spiros```\r\n\r\n- Force = Mass X Acceleration\r\n- Acceleration = Force/Mass\r\n\r\n- What is the NORMAL force?  Always = 1 (in our processing world)\r\n\r\n- Friction Algorithm (what is mag and direction of friction (always against the direction of velocity)):  Friction Force = -1 X (unit direction velocity vector) X the NORMAL force X the coefficient of friction\r\n\r\n```\r\nPVector friction = velocity.get();  // get a copy of velocity vector\r\nfriction.normalize();  // normalize the copied velocity vector to get its direction\r\nfriction.mult(-1);   // now take the direction and put it in the opposite direction (because friction acts AGAINST the direction of velocity)\r\nfloat coefficientOfFriction = .001;  // set the strength of the friction\r\nfriction.mult(coefficientOfFriction)  // the direction of friction and multiply by the magnitude set by the kind of substance causing the friction (the Coefficient of Friction)\r\n```\r\n\r\n- **Polar to Cartesian Cordinates**\r\n\t- SOHCAHTOA\r\n\t- y = radius * sin(theta)\r\n\t- x = radius * cos(theta)\r\n\r\n- The following statement will create a user defined function that will create Spirograph patterns:\r\n\r\n```\r\nspirograph = function (v_R, v_r, v_p, v_nRotations, s_color)\r\n{\r\n    t = vectorin(0, 0.05, 2 * pi * v_nRotations);:\r\n    x = (v_R + v_r) * cos(t) + v_p * cos((v_R + v_r) * t / v_r);:\r\n    y = (v_R + v_r)* sin(t) + v_p * sin((v_R + v_r) * t / v_r);:\r\n    plot(x, y, s_color):\r\n}\r\n```\r\n\t- To see this function in action, execute the following statement:\r\n\r\n>```spirograph(53, -29, 40, 30, gray)```\r\n\r\n\r\n###Examples:\r\n####Spirograph Examples:\r\n- [Spirograph Web App worth checking out](http://www.benjoffe.com/code/toys/spirograph)\r\n- [Epicycles On Epicycles, Cable Knots on Cable Knots | vimeo](https://vimeo.com/7757058)\r\n- [The 3D Spirograph Project | vimeo](https://vimeo.com/2228788)\r\n\t- The visual math of epicycloids. Nested rotational orbits produce emergent spiral designs in 3D.\r\n- [Vectors: Acceleration Towards the Mouse (Nature of Code) - Shiffman](https://vimeo.com/59028636)\r\n- [If Spirographs were 3D](http://matheminutes.blogspot.com/2012/01/if-spirograph-were-3d.html)\r\n- [Spirographs and the 3rd Dimensions | 3D printing](http://maxwelldemon.com/2010/01/14/spirographs-and-the-third-dimension/)\r\n- [Spirograph | Web App](http://wordsmith.org/~anu/java/spirograph.html#display)\r\n- [Spirograph in Code | OpenProcessing website](http://www.openprocessing.org/browse/?viewBy=tags&tag=spirograph)\r\n- [Spirographs Explained | Sam Brenner from ITP](http://samjbrenner.com/notes/processing-spirograph/)\r\n- [Simple Spirograph | Web App from Aquilax's Dev Blog](http://dev.horemag.net/2008/03/03/spirograph-with-processing/)\r\n- [Mathiversity | Spirograph Web App](http://mathiversity.com/Spirograph)\r\n- [Spirograph Web App](http://www.eddaardvark.co.uk/nc/sprog/index.html#x)\r\n\r\n####FlowField Examples:\r\n- [Flocking in FlowField  |  Flight 404 on Vimeo](https://vimeo.com/153453#)\r\n\t- [Flight 404 blog post about the Flocking Behaviors in a Flow Field](http://www.flight404.com/blog/?p=66)\r\n\t\t- In the original version, for some reason, I decided the best way to deal with the flowfield was to make a ton of vectors and stick them in the space. These vectors are stationary and only contain velocity information. I would use Perlin noise to adjust each vector’s velocity and just leave them there. Pretty much an invisible 3D array of floating arrows. I would then throw a bunch of objects in this 3D array and have each object check the nearest vector for its velocity information and apply this information to the objects own velocity.\r\n\t\t- Turns out, this was way more work than I needed. Instead, I should simply apply the Perlin noise data directly to my object’s velocity vectors and voila, done and done. And without needing to worry about placing thousands of vector arrows into a space that simply didnt need it. In a way, the Perlin noise data can represent an infinite space with an infinite number of vector arrows, and for cheap too.\r\n- [Flocking in 3D  |  Flight 404 for Eyeo 2012 Festival](https://vimeo.com/43802463)\r\n- [Shockwave |  Flight 404](https://vimeo.com/43802127)\r\n- [Benjamin Moore Commercial  |  rotating paint buckets](http://www.youtube.com/watch?v=i_kCJe_VZ-E)\r\n\r\n\r\n####FlowMaps, Reference Images:\r\n- [] add a method for \r\n\r\n####Theta as a function of Depth:\r\n\r\n\r\n###Future:\r\n- [] toxilib\r\n- [Flow no.1 The Kinect Projector Dance](http://princemio.net/portfolio/flow-1-kinect-projector-dance/)\r\n\t- Software Used for the project:\r\n\t\t- ofxOpenNI – created by gameoverhack – openNi wrapper to read captrued data from the kinect camera in realtime.\r\n\t\t- ofxCV – created by Kyle McDonald – fast openCV wrapper.\r\n\t\t- ofxFluidSolver – created by Memo Atken. After Years, it is still one of my favourite calculation models to illustrate continous flow of a dancer and graphics.\r\n\t\t- ofxUI – created by rezaali – having worked a lot in processing, i completly fell in love with this GUI library as it speeds up my tweaking processes. Its easy to use and fast to bind to variables.\r\n\r\n- **Particles Create Shape -> then use TEXTURE image:**\r\n\t- currently particles from t1-tn create a line\r\n\t- use clusters of particles **to form a shape**\r\n\t- then fill that shape with a texture randomly selected from an Emblem\r\n\r\n- **FLOW MAPS**\r\n\t- use SNAPS from OmiCron in addition to perlin noise field\r\n\t- **use RVL video archives to inform flow field**\r\n\r\n_____________________\r\n\r\n###Next Steps:\r\n- [] Setup OmiCron:\r\n\t- [x] Run Calibration with Processing.  Systems Check\r\n\t- [x] Tighten bolts on OmiCron pedestal\r\n\t- [x] review RotaDeva code for input flow.\r\n\t- [] Write the code that treats OmiCron as if it were a variety of forces.  \r\n\t- ```omiCron.KnobLeftRed(); // returns a PVector reading for Magnitude, direction, velocity, etc```\r\n\t- ```omiCron.lookup(KnobFoo); // returns an array of PVectors?????```\r\n\t- [] make a version for SpiroLight\r\n- [] rewrite the centerPiece_SpiroLight to include OmiCron\r\n\t- [] scale model using foam core or construction paper??\r\n\t- [] get all the inputs with stationary SpiroLight first Tiers 1-3","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}